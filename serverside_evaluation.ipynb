{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2bb01c",
   "metadata": {},
   "source": [
    "# OPS-SAT case serverside evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9611e0",
   "metadata": {},
   "source": [
    "ESA's [Kelvins](https://kelvins.esa.int) competition \"[the OPS-SAT case](https://kelvins.esa.int/opssat/home/)\" is a novel data-centric challenge that asks you to work with the raw data of a satellite and very few provided labels to find the best parameters for a given machine learning model. Compared to previous competitions on Kelvins (like the [Pose Estimation](https://kelvins.esa.int/pose-estimation-2021/) or the [Proba-V Super-resolution challenge](https://kelvins.esa.int/proba-v-super-resolution/)) where the test-set is provided and the infered results are submitted, for the OPS-SAT case, we will run inference on the Kelvins server directly! To help you understand what is happening with your submission, this notebook replicates all steps that are executed by the script on our server, including computation of the scoring metric. We hope that it will be useful to you to avoid/find any bugs and prepare the best submission you can!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993066d",
   "metadata": {},
   "source": [
    "# 1. Module imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafdd0",
   "metadata": {},
   "source": [
    "If you do not have a GPU, uncomment and run the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a045946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from efficientnet_lite import EfficientNetLiteB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c369e7",
   "metadata": {},
   "source": [
    "# 2. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ad937",
   "metadata": {},
   "source": [
    "The next function is used to load evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_from_path(dataset_path):\n",
    "    \"\"\" Get images from path and normalize them applying channel-level normalization. \"\"\"\n",
    "\n",
    "    # loading all images in one large batch\n",
    "    tf_eval_data = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=input_shape[:2], shuffle=False, \n",
    "                                                               batch_size=100000)\n",
    "\n",
    "    # extract images and targets\n",
    "    for tf_eval_images, tf_eval_targets in tf_eval_data:\n",
    "        break\n",
    "\n",
    "    return tf.convert_to_tensor(tf_eval_images), tf_eval_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e397f",
   "metadata": {},
   "source": [
    "# 3. Producing a submission (competitor side)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03702ebb",
   "metadata": {},
   "source": [
    "The network architecture used for OPS-SAT is **EfficientNetLite0**. We would like to thank Sebastian for making a Keras implementation of EfficientNetLite publicly available under the Apache 2.0 License: https://github.com/sebastian-sz/efficientnet-lite-keras. Our Version of this code has been modified to better fit our purposes. For example, we removed the ReLU \"stem_activation\" to better match a related efficientnet pytorch implementation. In any way, **you have to use the model architecture that we provide in our [starter-kit](https://gitlab.com/EuropeanSpaceAgency/the_opssat_case_starter_kit).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (200, 200, 3)   # input_shape is (height, width, number of channels) for images\n",
    "num_classes = 8\n",
    "#Loading model\n",
    "model = EfficientNetLiteB0(classes=num_classes, weights=None, input_shape=input_shape, classifier_activation=None)\n",
    "#Printing model summary.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc20e92",
   "metadata": {},
   "source": [
    "With this model and the dataset provided, please do your best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data, data augmentation, training, overfitting, transfer-learning etc.\n",
    "#x_train, y_train = ...\n",
    "#model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e54a72",
   "metadata": {},
   "source": [
    "After your model has been trained, all parameters need to be exported in HDF5-format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe14c9",
   "metadata": {},
   "source": [
    "The corresponding file should be around 13MB in size. You can now upload this on the corresponding [Kelvins submission page](https://kelvins.esa.int/opssat/submission/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180524eb",
   "metadata": {},
   "source": [
    "# 4. Evaluating your submission (server side)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60073544",
   "metadata": {},
   "source": [
    "## 4.1 submission validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4552e",
   "metadata": {},
   "source": [
    "Our validation script needs to check whether the submitted HDF5-file (referred to by the `file` variable in the following) is compatible with the predefined model. This is done simply by loading in the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0db747",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetLiteB0(classes=num_classes, weights=None, input_shape=input_shape, classifier_activation=None)\n",
    "model.load_weights(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44aac00",
   "metadata": {},
   "source": [
    "If `model.load_weights(file)` throws an Exception, your submission is invalid. Otherwise, it will be passed on to the **scoring** script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the evaluation dataset is a secret ;)\n",
    "dataset_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in hidden OPS_SAT data\n",
    "images, targets = get_images_from_path(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing base model\n",
    "model = EfficientNetLiteB0(classes=num_classes, weights=None, input_shape=input_shape, classifier_activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in weights\n",
    "model.load_weights(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ed277",
   "metadata": {},
   "source": [
    "## 4.2 Computation of the Keras (unquantized) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bfaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model shall be compiled before the inference.\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e891fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(targets.shape, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference loop\n",
    "for e, (image, target) in enumerate(zip(images, targets)):\n",
    "    image = np.expand_dims(np.array(image), axis=0)\n",
    "    output = model.predict(image)\n",
    "    predictions[e] = np.squeeze(output).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793aa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras model score\n",
    "score_keras = 1 - cohen_kappa_score(targets.numpy(), predictions)\n",
    "print(score_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6d51d",
   "metadata": {},
   "source": [
    "## 4.3 Computation of the float16 quantized score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805268be",
   "metadata": {},
   "source": [
    "The computation of the quantized score involves several steps of serialization and model conversion so that we can run inference on the tensorflow-lite interpreter. This closely resembles the actual capabilities of the OPS-SAT platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0626a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '.'\n",
    "tflite_model_path = './tflite_mock_model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialization of model in preparation for the tf-lite conversion\n",
    "tf.saved_model.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3997144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model conversion to 16bit float\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] \n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96328323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialization of tflite model in preparation for inference\n",
    "with open(tflite_model_path, 'wb') as fp:\n",
    "    fp.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with tf-lite interpreter\n",
    "interpreter = tf.lite.Interpreter(tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(targets.shape, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a47d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference loop\n",
    "for e, (image, target) in enumerate(zip(images, targets)):\n",
    "    image = np.expand_dims(np.array(image, dtype = input_details[\"dtype\"]), axis=0)\n",
    "    interpreter.set_tensor(input_details[\"index\"], image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    predictions[e] = np.squeeze(output).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantized tf lite model score\n",
    "score_float16 = 1 - cohen_kappa_score(targets.numpy(), predictions)\n",
    "print(score_float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce59621",
   "metadata": {},
   "source": [
    "Depending on the workload of out server, the computation of the **unquantized** and the **float16 quantized** score might take **several minutes** so please be patient.\n",
    "\n",
    "If no exception occured, your submission will be scored in the [Leaderboard](https://kelvins.esa.int/opssat/leaderboard/leaderboard).\n",
    "\n",
    "Your position in the Leaderboard is determined by the float16 score. We report the Keras score nevertheless, as it is interesting for us to study the quantization error.\n",
    "\n",
    "The Leaderboard will show the **best float16 score** of each team and the time at which their best and their last submission was evaluated. Thus, in order to check whether your last submission was evaluated, you should **check the \"Last Submission\" column** in the Leaderboard. Please understand that we do not provide scores for individual submissions to prevent excessive probing of the test set. \n",
    "\n",
    "Lastly, we would like to state that we did our best to test this evaluation system, but it is the first time we are doing this setup on Kelvins and the risk that something goes wrong can never be fully eliminated :(\n",
    "\n",
    "Thus, **if even after about half an hour the \"Last Submission\" column is not updated** there was probably an unaccounted exception within the scoring. Should this be the case, please let us know by opening a Thread in the [Discussion board](https://kelvins.esa.int/opssat/discussion/). To avoid unnecessary back and forth we appreciate if you would state in this thread:\n",
    "\n",
    "* name of your team\n",
    "* time of your submission\n",
    "* any error messages or observations that you believe might help\n",
    "\n",
    "If this happens, your submission has been received, so there is no need to provide it nor should you, since the Discussion board is public! We will debug your submission on our side and get back to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf763a54",
   "metadata": {},
   "source": [
    "# 5. Differences between this notebook, server-script and satellite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de7cc6",
   "metadata": {},
   "source": [
    "Some differences between this notebook, the server-side script and the actual satellite exist, mostly related to the underlying hardware and software dependencies. \n",
    "\n",
    "The main difference between our server-script and this notebook are additional checks and Kelvins specific commands (housekeeping) that we omitted here for clarity. Moreover, the test-set used to compute your score is **reduced by 50% during the competition**. After the submission period of the competition ends, **your best scoring submission will be re-evaluated on 100% of the held-out test-set**. These scores will be published in a separate Results leaderboard that will be used to determine the final ranking.\n",
    "\n",
    "During our tests we found only a negligible numerical difference when evaluating models using tensorflow on different hardware/software and in our opinion it is not needed to replicate the exact environment to achieve meaningful results. If you nevertheless want to be as close as possible to our server setup, we are using\n",
    "\n",
    "* `python 3.9.10`\n",
    "* `tensorflow 2.7.0`\n",
    "* `numpy 1.21.1`\n",
    "* `scikit-learn 1.0.2`\n",
    "\n",
    "running on a **Debian-based Linux** distribution.\n",
    "\n",
    "OPS-SAT itself will have a slightly different execution environment, which has no relevance for the competition. Should you win the competition and get the chance to fly your model in space, we will work on that together. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
