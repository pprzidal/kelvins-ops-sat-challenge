{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d620e445",
   "metadata": {},
   "source": [
    "# OPS-SAT Pytorch to TF model conversion notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4245377",
   "metadata": {},
   "source": [
    "ESA's [Kelvins](https://kelvins.esa.int) competition \"[the OPS-SAT case](https://kelvins.esa.int/opssat/home/)\" is a novel data-centric challenge that asks you to work with the raw data of a satellite and very few provided labels to find the best parameters for a given machine learning model. <br> Compared to previous competitions on Kelvins (like the [Pose Estimation](https://kelvins.esa.int/pose-estimation-2021/) or the [Proba-V Super-resolution challenge](https://kelvins.esa.int/proba-v-super-resolution/)) where the test-set is provided and the infered results are submitted, for the OPS-SAT case, we will run inference on the Kelvins server directly! To this aim, you need to use to submit the parameters of a [Keras](https://keras.io/api/models/model/) implementation of `EfficientNet-lite-0` (`EfficientNetLiteB0` model), included in the file `efficientnet_lite.py`. <br>The latter is provided in our [starter-kit on Gitlab](https://gitlab.com/EuropeanSpaceAgency/the_opssat_case_starter_kit), and it is based on [efficientnet-lite-keras](https://github.com/sebastian-sz/efficientnet-lite-keras), with some modifications. <br><br>To facilitate [PyTorch](https://pytorch.org/) developers, this notebook provide some utils to convert a [PyTorch](https://pytorch.org/)  model (file `.pth`) based on [efficientnet-lite-pytorch](https://pypi.org/project/efficientnet-lite-pytorch/) (`Pytorch` implementation of `EfficientNet-lite-0`) to the requested `EfficientNetLiteB0`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa78c41",
   "metadata": {},
   "source": [
    "**DISCLAIMER**: Comparing `efficientnet-lite-pytorch` and `EfficientNetLiteB0` models (as for the original implementation [efficientnet-lite-keras](https://github.com/sebastian-sz/efficientnet-lite-keras)), we noticed some differences in way padding is performed. This fact leads to a different output shape after the `_blocks[5]._depthwise_conv` layer in `PyTorch`, matching the `Keras` `block4a_dwconv` layer (`PyTorch` output shape, [1, 240, 12, 12]  vs `Keras` output shape, [1, 240, 13, 13]). \n",
    "**This could impact the performance of your model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b70e2",
   "metadata": {},
   "source": [
    "# 1. Module imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3a34e",
   "metadata": {},
   "source": [
    "If you do not have a GPU, uncomment and run the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579bff7",
   "metadata": {},
   "source": [
    "Other imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet_lite_pytorch\n",
    "from efficientnet_lite0_pytorch_model import EfficientnetLite0ModelFile\n",
    "from efficientnet_lite import EfficientNetLiteB0\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98840df6",
   "metadata": {},
   "source": [
    "# 2. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b0689",
   "metadata": {},
   "source": [
    "The next function is used to pass the trained parameters of your `Pytorch` model to the requested `Keras` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_efficientnet_lite0_parameters(model_pytorch, model_tf):\n",
    "    \"\"\"Converts a trained EfficientNet_lite0 Pytorch by transferring parameters to the untrained EfficientNet_lite0 Tensorflow model.\n",
    "\n",
    "    Args:\n",
    "        model_pytorch (pytorch model): trained EfficientNet_lite0 Pytorch model.\n",
    "        model_tf (tf model): untrained EfficientNet_lite0 Tensorflow model.\n",
    "\n",
    "    Returns:\n",
    "        model_tf: EfficientNet_Lite 0 with trained weights in Pytorch.\n",
    "    \"\"\"\n",
    "    #Torch layer lists\n",
    "    model_pytorch_layers=[model_pytorch._conv_stem, model_pytorch._bn0, model_pytorch._blocks[0]._depthwise_conv,model_pytorch._blocks[0]._bn1,model_pytorch._blocks[0]._project_conv, model_pytorch._blocks[0]._bn2, model_pytorch._blocks[0]._swish,model_pytorch._blocks[1:],model_pytorch._conv_head, model_pytorch._bn1, model_pytorch._avg_pooling, model_pytorch._dropout, model_pytorch._fc, model_pytorch._swish]\n",
    "    mb_block_layers=[\"_expand_conv\",\"_bn0\",\"_depthwise_conv\",\"_bn1\",\"_project_conv\",\"_bn2\",\"_swish\"]\n",
    "    weight_list=[]\n",
    "    n=0\n",
    "    print(\"Extracting Pytorch model parameters...\")\n",
    "    #Extracting pytorch layers\n",
    "    for layer in model_pytorch_layers[:-1]:\n",
    "        if n == 7:\n",
    "            for n_mb_blocks in range(len(layer)):\n",
    "                m_block=layer[n_mb_blocks]\n",
    "                for n_layer_mb_conv in range(len(mb_block_layers[:-1])):\n",
    "                    layer_block_l=getattr(m_block,mb_block_layers[n_layer_mb_conv])\n",
    "                    if (n_layer_mb_conv != 1) and (n_layer_mb_conv != 3) and (n_layer_mb_conv != 5):\n",
    "                        weight_list.append([layer_block_l.weight, layer_block_l.bias])\n",
    "                    else:\n",
    "                        weight_list.append([layer_block_l.weight, layer_block_l.bias, layer_block_l.momentum, layer_block_l.eps, layer_block_l.running_mean, layer_block_l.running_var])\n",
    "                        \n",
    "        elif (n == 1) or (n == 3) or (n == 5) or (n == 9):\n",
    "            weight_list.append([layer.weight, layer.bias, layer.momentum, layer.eps, layer.running_mean, layer.running_var])\n",
    "        elif (n != 6) and (n != 10) and (n != 11):\n",
    "            weight_list.append([layer.weight, layer.bias])\n",
    "        n+=1\n",
    "    \n",
    "    print(\"Converting layers...\")\n",
    "    last_tf_layer=-1\n",
    "    for k in range(len(weight_list)):\n",
    "        w_shape=weight_list[k][0].shape\n",
    "        if len(w_shape) == 4:\n",
    "            w=weight_list[k][0].permute(2, 3, 1, 0)\n",
    "        else:\n",
    "            w=weight_list[k][0]\n",
    "            \n",
    "        if not(weight_list[k][1] is None):\n",
    "            b=weight_list[k][1]\n",
    "        else:\n",
    "            b=None\n",
    "                \n",
    "        for n in range(last_tf_layer+1,len(model_tf.layers)):\n",
    "            layer=model_tf.layers[n]\n",
    "            if isinstance(layer, tf.keras.layers.DepthwiseConv2D ) or isinstance(layer, tf.keras.layers.Conv2D ) or isinstance(layer, tf.keras.layers.Dense):\n",
    "                if isinstance(layer, tf.keras.layers.DepthwiseConv2D ):\n",
    "                    w=weight_list[k][0].permute(2, 3, 0, 1)\n",
    "                elif isinstance(layer, tf.keras.layers.Dense):\n",
    "                    w=weight_list[k][0].permute(1,0)\n",
    "                    \n",
    "                if not(b is None):\n",
    "                    model_tf.layers[n].set_weights([w.detach().cpu().numpy(), b.detach().cpu().numpy()]) \n",
    "                else:\n",
    "                    model_tf.layers[n].set_weights([w.detach().cpu().numpy()])\n",
    "                last_tf_layer=n\n",
    "                break\n",
    "                \n",
    "            elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                gamma=weight_list[k][0].detach().cpu().numpy()\n",
    "                beta=weight_list[k][1].detach().cpu().numpy()\n",
    "                momentum=weight_list[k][2]\n",
    "                epsilon=weight_list[k][3]\n",
    "                running_mean=weight_list[k][4].detach().cpu().numpy()\n",
    "                running_var=weight_list[k][5].detach().cpu().numpy()\n",
    "                model_tf.layers[n].set_weights([gamma, beta, running_mean, running_var])\n",
    "                model_tf.layers[n].momentum=momentum\n",
    "                model_tf.layers[n].epsilon=epsilon\n",
    "                \n",
    "                last_tf_layer=n\n",
    "                break\n",
    "    print(\"Model converted.\")\n",
    "    return model_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de603cf8",
   "metadata": {},
   "source": [
    "# 3. Loading Pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5470b9",
   "metadata": {},
   "source": [
    "Instantiating an `efficientnet_lite_pytorch` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf470881",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = EfficientnetLite0ModelFile.get_model_file_path()\n",
    "model_pytorch= efficientnet_lite_pytorch.EfficientNet.from_pretrained('efficientnet-lite0', weights_path = weights_path,num_classes=8, in_channels=3)\n",
    "model_pytorch.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b5934",
   "metadata": {},
   "source": [
    "Uncomment next line and update the path to trained '`efficientnet_lite_pytorch` (`.pth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path=\"Path to the .pth file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffccd3d",
   "metadata": {},
   "source": [
    "If you need to load your model on the CPU, please change `torch.load(checkpoint_path) ` to `torch.load(checkpoint_path, map_location=torch.device('cpu'))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading model\n",
    "model_pytorch.load_state_dict(torch.load(checkpoint_path)['eval_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c3bc31",
   "metadata": {},
   "source": [
    "# 4. Loading Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0498f",
   "metadata": {},
   "source": [
    "Instantiating an `EfficientNetLiteB0` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf=EfficientNetLiteB0(classes=8, weights=None, input_shape=(200, 200,3), classifier_activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564b404",
   "metadata": {},
   "source": [
    "# 5. Pytorch to Keras conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf2465",
   "metadata": {},
   "source": [
    "The next function perses the trained `Pytorch` model, extracts its parameters and load them into the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf=convert_efficientnet_lite0_parameters(model_pytorch, model_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf19c1",
   "metadata": {},
   "source": [
    "# 6. Save output Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94979453",
   "metadata": {},
   "source": [
    "Saving the parameters of the converted model as `.h5` file. Please, adjust `output_path` with the target path of the `.h5` file and uncomment the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path=\"Path to the output .h5 file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224edf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving output keras model.\n",
    "model_tf.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
